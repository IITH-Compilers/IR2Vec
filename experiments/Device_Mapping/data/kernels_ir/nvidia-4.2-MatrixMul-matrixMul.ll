; ModuleID = 'nvidia-4.2-MatrixMul-matrixMul.cl'
source_filename = "nvidia-4.2-MatrixMul-matrixMul.cl"
target datalayout = "e-m:o-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-apple-macosx10.13.0"

; Function Attrs: nounwind ssp uwtable
define spir_kernel void @matrixMul(float* nocapture, float* nocapture readonly, float* nocapture readonly, float* nocapture, float* nocapture, i32, i32, i32) local_unnamed_addr #0 !kernel_arg_addr_space !4 !kernel_arg_access_qual !5 !kernel_arg_type !6 !kernel_arg_base_type !6 !kernel_arg_type_qual !7 {
  %9 = tail call i64 @_Z12get_group_idj(i32 1) #4
  %10 = trunc i64 %9 to i32
  %11 = tail call i64 @_Z12get_local_idj(i32 0) #4
  %12 = trunc i64 %11 to i32
  %13 = tail call i64 @_Z12get_local_idj(i32 1) #4
  %14 = trunc i64 %13 to i32
  %15 = shl nsw i32 %5, 6
  %16 = mul nsw i32 %15, %10
  %17 = icmp sgt i32 %5, 0
  br i1 %17, label %18, label %296

; <label>:18:                                     ; preds = %8
  %19 = shl i32 %6, 6
  %20 = add nsw i32 %16, %5
  %21 = tail call i64 @_Z12get_group_idj(i32 0) #4
  %22 = trunc i64 %21 to i32
  %23 = shl nsw i32 %22, 6
  %24 = mul nsw i32 %14, %5
  %25 = add i32 %24, %12
  %26 = shl nsw i32 %14, 6
  %27 = add nsw i32 %26, %12
  %28 = sext i32 %27 to i64
  %29 = getelementptr inbounds float, float* %3, i64 %28
  %30 = bitcast float* %29 to i32*
  %31 = mul nsw i32 %14, %6
  %32 = add i32 %31, %12
  %33 = getelementptr inbounds float, float* %4, i64 %28
  %34 = bitcast float* %33 to i32*
  %35 = sext i32 %26 to i64
  %36 = shl i64 %11, 32
  %37 = ashr exact i64 %36, 32
  %38 = getelementptr inbounds float, float* %3, i64 %35
  %39 = sext i32 %23 to i64
  %40 = sext i32 %19 to i64
  %41 = sext i32 %16 to i64
  %42 = sext i32 %20 to i64
  %43 = getelementptr inbounds float, float* %4, i64 %37
  %44 = or i64 %35, 1
  %45 = getelementptr inbounds float, float* %3, i64 %44
  %46 = add nsw i64 %37, 64
  %47 = getelementptr inbounds float, float* %4, i64 %46
  %48 = or i64 %35, 2
  %49 = getelementptr inbounds float, float* %3, i64 %48
  %50 = add nsw i64 %37, 128
  %51 = getelementptr inbounds float, float* %4, i64 %50
  %52 = or i64 %35, 3
  %53 = getelementptr inbounds float, float* %3, i64 %52
  %54 = add nsw i64 %37, 192
  %55 = getelementptr inbounds float, float* %4, i64 %54
  %56 = or i64 %35, 4
  %57 = getelementptr inbounds float, float* %3, i64 %56
  %58 = add nsw i64 %37, 256
  %59 = getelementptr inbounds float, float* %4, i64 %58
  %60 = or i64 %35, 5
  %61 = getelementptr inbounds float, float* %3, i64 %60
  %62 = add nsw i64 %37, 320
  %63 = getelementptr inbounds float, float* %4, i64 %62
  %64 = or i64 %35, 6
  %65 = getelementptr inbounds float, float* %3, i64 %64
  %66 = add nsw i64 %37, 384
  %67 = getelementptr inbounds float, float* %4, i64 %66
  %68 = or i64 %35, 7
  %69 = getelementptr inbounds float, float* %3, i64 %68
  %70 = add nsw i64 %37, 448
  %71 = getelementptr inbounds float, float* %4, i64 %70
  %72 = or i64 %35, 8
  %73 = getelementptr inbounds float, float* %3, i64 %72
  %74 = add nsw i64 %37, 512
  %75 = getelementptr inbounds float, float* %4, i64 %74
  %76 = or i64 %35, 9
  %77 = getelementptr inbounds float, float* %3, i64 %76
  %78 = add nsw i64 %37, 576
  %79 = getelementptr inbounds float, float* %4, i64 %78
  %80 = or i64 %35, 10
  %81 = getelementptr inbounds float, float* %3, i64 %80
  %82 = add nsw i64 %37, 640
  %83 = getelementptr inbounds float, float* %4, i64 %82
  %84 = or i64 %35, 11
  %85 = getelementptr inbounds float, float* %3, i64 %84
  %86 = add nsw i64 %37, 704
  %87 = getelementptr inbounds float, float* %4, i64 %86
  %88 = or i64 %35, 12
  %89 = getelementptr inbounds float, float* %3, i64 %88
  %90 = add nsw i64 %37, 768
  %91 = getelementptr inbounds float, float* %4, i64 %90
  %92 = or i64 %35, 13
  %93 = getelementptr inbounds float, float* %3, i64 %92
  %94 = add nsw i64 %37, 832
  %95 = getelementptr inbounds float, float* %4, i64 %94
  %96 = or i64 %35, 14
  %97 = getelementptr inbounds float, float* %3, i64 %96
  %98 = add nsw i64 %37, 896
  %99 = getelementptr inbounds float, float* %4, i64 %98
  %100 = or i64 %35, 15
  %101 = getelementptr inbounds float, float* %3, i64 %100
  %102 = add nsw i64 %37, 960
  %103 = getelementptr inbounds float, float* %4, i64 %102
  %104 = or i64 %35, 16
  %105 = getelementptr inbounds float, float* %3, i64 %104
  %106 = add nsw i64 %37, 1024
  %107 = getelementptr inbounds float, float* %4, i64 %106
  %108 = or i64 %35, 17
  %109 = getelementptr inbounds float, float* %3, i64 %108
  %110 = add nsw i64 %37, 1088
  %111 = getelementptr inbounds float, float* %4, i64 %110
  %112 = or i64 %35, 18
  %113 = getelementptr inbounds float, float* %3, i64 %112
  %114 = add nsw i64 %37, 1152
  %115 = getelementptr inbounds float, float* %4, i64 %114
  %116 = or i64 %35, 19
  %117 = getelementptr inbounds float, float* %3, i64 %116
  %118 = add nsw i64 %37, 1216
  %119 = getelementptr inbounds float, float* %4, i64 %118
  %120 = or i64 %35, 20
  %121 = getelementptr inbounds float, float* %3, i64 %120
  %122 = add nsw i64 %37, 1280
  %123 = getelementptr inbounds float, float* %4, i64 %122
  %124 = or i64 %35, 21
  %125 = getelementptr inbounds float, float* %3, i64 %124
  %126 = add nsw i64 %37, 1344
  %127 = getelementptr inbounds float, float* %4, i64 %126
  %128 = or i64 %35, 22
  %129 = getelementptr inbounds float, float* %3, i64 %128
  %130 = add nsw i64 %37, 1408
  %131 = getelementptr inbounds float, float* %4, i64 %130
  %132 = or i64 %35, 23
  %133 = getelementptr inbounds float, float* %3, i64 %132
  %134 = add nsw i64 %37, 1472
  %135 = getelementptr inbounds float, float* %4, i64 %134
  %136 = or i64 %35, 24
  %137 = getelementptr inbounds float, float* %3, i64 %136
  %138 = add nsw i64 %37, 1536
  %139 = getelementptr inbounds float, float* %4, i64 %138
  %140 = or i64 %35, 25
  %141 = getelementptr inbounds float, float* %3, i64 %140
  %142 = add nsw i64 %37, 1600
  %143 = getelementptr inbounds float, float* %4, i64 %142
  %144 = or i64 %35, 26
  %145 = getelementptr inbounds float, float* %3, i64 %144
  %146 = add nsw i64 %37, 1664
  %147 = getelementptr inbounds float, float* %4, i64 %146
  %148 = or i64 %35, 27
  %149 = getelementptr inbounds float, float* %3, i64 %148
  %150 = add nsw i64 %37, 1728
  %151 = getelementptr inbounds float, float* %4, i64 %150
  %152 = or i64 %35, 28
  %153 = getelementptr inbounds float, float* %3, i64 %152
  %154 = add nsw i64 %37, 1792
  %155 = getelementptr inbounds float, float* %4, i64 %154
  %156 = or i64 %35, 29
  %157 = getelementptr inbounds float, float* %3, i64 %156
  %158 = add nsw i64 %37, 1856
  %159 = getelementptr inbounds float, float* %4, i64 %158
  %160 = or i64 %35, 30
  %161 = getelementptr inbounds float, float* %3, i64 %160
  %162 = add nsw i64 %37, 1920
  %163 = getelementptr inbounds float, float* %4, i64 %162
  %164 = or i64 %35, 31
  %165 = getelementptr inbounds float, float* %3, i64 %164
  %166 = add nsw i64 %37, 1984
  %167 = getelementptr inbounds float, float* %4, i64 %166
  %168 = or i64 %35, 32
  %169 = getelementptr inbounds float, float* %3, i64 %168
  %170 = add nsw i64 %37, 2048
  %171 = getelementptr inbounds float, float* %4, i64 %170
  %172 = or i64 %35, 33
  %173 = getelementptr inbounds float, float* %3, i64 %172
  %174 = add nsw i64 %37, 2112
  %175 = getelementptr inbounds float, float* %4, i64 %174
  %176 = or i64 %35, 34
  %177 = getelementptr inbounds float, float* %3, i64 %176
  %178 = add nsw i64 %37, 2176
  %179 = getelementptr inbounds float, float* %4, i64 %178
  %180 = or i64 %35, 35
  %181 = getelementptr inbounds float, float* %3, i64 %180
  %182 = add nsw i64 %37, 2240
  %183 = getelementptr inbounds float, float* %4, i64 %182
  %184 = or i64 %35, 36
  %185 = getelementptr inbounds float, float* %3, i64 %184
  %186 = add nsw i64 %37, 2304
  %187 = getelementptr inbounds float, float* %4, i64 %186
  %188 = or i64 %35, 37
  %189 = getelementptr inbounds float, float* %3, i64 %188
  %190 = add nsw i64 %37, 2368
  %191 = getelementptr inbounds float, float* %4, i64 %190
  %192 = or i64 %35, 38
  %193 = getelementptr inbounds float, float* %3, i64 %192
  %194 = add nsw i64 %37, 2432
  %195 = getelementptr inbounds float, float* %4, i64 %194
  %196 = or i64 %35, 39
  %197 = getelementptr inbounds float, float* %3, i64 %196
  %198 = add nsw i64 %37, 2496
  %199 = getelementptr inbounds float, float* %4, i64 %198
  %200 = or i64 %35, 40
  %201 = getelementptr inbounds float, float* %3, i64 %200
  %202 = add nsw i64 %37, 2560
  %203 = getelementptr inbounds float, float* %4, i64 %202
  %204 = or i64 %35, 41
  %205 = getelementptr inbounds float, float* %3, i64 %204
  %206 = add nsw i64 %37, 2624
  %207 = getelementptr inbounds float, float* %4, i64 %206
  %208 = or i64 %35, 42
  %209 = getelementptr inbounds float, float* %3, i64 %208
  %210 = add nsw i64 %37, 2688
  %211 = getelementptr inbounds float, float* %4, i64 %210
  %212 = or i64 %35, 43
  %213 = getelementptr inbounds float, float* %3, i64 %212
  %214 = add nsw i64 %37, 2752
  %215 = getelementptr inbounds float, float* %4, i64 %214
  %216 = or i64 %35, 44
  %217 = getelementptr inbounds float, float* %3, i64 %216
  %218 = add nsw i64 %37, 2816
  %219 = getelementptr inbounds float, float* %4, i64 %218
  %220 = or i64 %35, 45
  %221 = getelementptr inbounds float, float* %3, i64 %220
  %222 = add nsw i64 %37, 2880
  %223 = getelementptr inbounds float, float* %4, i64 %222
  %224 = or i64 %35, 46
  %225 = getelementptr inbounds float, float* %3, i64 %224
  %226 = add nsw i64 %37, 2944
  %227 = getelementptr inbounds float, float* %4, i64 %226
  %228 = or i64 %35, 47
  %229 = getelementptr inbounds float, float* %3, i64 %228
  %230 = add nsw i64 %37, 3008
  %231 = getelementptr inbounds float, float* %4, i64 %230
  %232 = or i64 %35, 48
  %233 = getelementptr inbounds float, float* %3, i64 %232
  %234 = add nsw i64 %37, 3072
  %235 = getelementptr inbounds float, float* %4, i64 %234
  %236 = or i64 %35, 49
  %237 = getelementptr inbounds float, float* %3, i64 %236
  %238 = add nsw i64 %37, 3136
  %239 = getelementptr inbounds float, float* %4, i64 %238
  %240 = or i64 %35, 50
  %241 = getelementptr inbounds float, float* %3, i64 %240
  %242 = add nsw i64 %37, 3200
  %243 = getelementptr inbounds float, float* %4, i64 %242
  %244 = or i64 %35, 51
  %245 = getelementptr inbounds float, float* %3, i64 %244
  %246 = add nsw i64 %37, 3264
  %247 = getelementptr inbounds float, float* %4, i64 %246
  %248 = or i64 %35, 52
  %249 = getelementptr inbounds float, float* %3, i64 %248
  %250 = add nsw i64 %37, 3328
  %251 = getelementptr inbounds float, float* %4, i64 %250
  %252 = or i64 %35, 53
  %253 = getelementptr inbounds float, float* %3, i64 %252
  %254 = add nsw i64 %37, 3392
  %255 = getelementptr inbounds float, float* %4, i64 %254
  %256 = or i64 %35, 54
  %257 = getelementptr inbounds float, float* %3, i64 %256
  %258 = add nsw i64 %37, 3456
  %259 = getelementptr inbounds float, float* %4, i64 %258
  %260 = or i64 %35, 55
  %261 = getelementptr inbounds float, float* %3, i64 %260
  %262 = add nsw i64 %37, 3520
  %263 = getelementptr inbounds float, float* %4, i64 %262
  %264 = or i64 %35, 56
  %265 = getelementptr inbounds float, float* %3, i64 %264
  %266 = add nsw i64 %37, 3584
  %267 = getelementptr inbounds float, float* %4, i64 %266
  %268 = or i64 %35, 57
  %269 = getelementptr inbounds float, float* %3, i64 %268
  %270 = add nsw i64 %37, 3648
  %271 = getelementptr inbounds float, float* %4, i64 %270
  %272 = or i64 %35, 58
  %273 = getelementptr inbounds float, float* %3, i64 %272
  %274 = add nsw i64 %37, 3712
  %275 = getelementptr inbounds float, float* %4, i64 %274
  %276 = or i64 %35, 59
  %277 = getelementptr inbounds float, float* %3, i64 %276
  %278 = add nsw i64 %37, 3776
  %279 = getelementptr inbounds float, float* %4, i64 %278
  %280 = or i64 %35, 60
  %281 = getelementptr inbounds float, float* %3, i64 %280
  %282 = add nsw i64 %37, 3840
  %283 = getelementptr inbounds float, float* %4, i64 %282
  %284 = or i64 %35, 61
  %285 = getelementptr inbounds float, float* %3, i64 %284
  %286 = add nsw i64 %37, 3904
  %287 = getelementptr inbounds float, float* %4, i64 %286
  %288 = or i64 %35, 62
  %289 = getelementptr inbounds float, float* %3, i64 %288
  %290 = add nsw i64 %37, 3968
  %291 = getelementptr inbounds float, float* %4, i64 %290
  %292 = or i64 %35, 63
  %293 = getelementptr inbounds float, float* %3, i64 %292
  %294 = add nsw i64 %37, 4032
  %295 = getelementptr inbounds float, float* %4, i64 %294
  br label %301

; <label>:296:                                    ; preds = %301, %8
  %297 = phi float [ 0.000000e+00, %8 ], [ %508, %301 ]
  %298 = tail call i64 @_Z13get_global_idj(i32 1) #4
  %299 = sext i32 %7 to i64
  %300 = icmp ult i64 %298, %299
  br i1 %300, label %512, label %518

; <label>:301:                                    ; preds = %18, %301
  %302 = phi i64 [ %41, %18 ], [ %509, %301 ]
  %303 = phi i64 [ %39, %18 ], [ %510, %301 ]
  %304 = phi float [ 0.000000e+00, %18 ], [ %508, %301 ]
  %305 = trunc i64 %302 to i32
  %306 = add i32 %25, %305
  %307 = sext i32 %306 to i64
  %308 = getelementptr inbounds float, float* %1, i64 %307
  %309 = bitcast float* %308 to i32*
  %310 = load i32, i32* %309, align 4, !tbaa !8
  store i32 %310, i32* %30, align 4, !tbaa !8
  %311 = trunc i64 %303 to i32
  %312 = add i32 %32, %311
  %313 = sext i32 %312 to i64
  %314 = getelementptr inbounds float, float* %2, i64 %313
  %315 = bitcast float* %314 to i32*
  %316 = load i32, i32* %315, align 4, !tbaa !8
  store i32 %316, i32* %34, align 4, !tbaa !8
  tail call void @_Z7barrierj(i32 1) #5
  %317 = load float, float* %38, align 4, !tbaa !8
  %318 = load float, float* %43, align 4, !tbaa !8
  %319 = tail call float @llvm.fmuladd.f32(float %317, float %318, float %304)
  %320 = load float, float* %45, align 4, !tbaa !8
  %321 = load float, float* %47, align 4, !tbaa !8
  %322 = tail call float @llvm.fmuladd.f32(float %320, float %321, float %319)
  %323 = load float, float* %49, align 4, !tbaa !8
  %324 = load float, float* %51, align 4, !tbaa !8
  %325 = tail call float @llvm.fmuladd.f32(float %323, float %324, float %322)
  %326 = load float, float* %53, align 4, !tbaa !8
  %327 = load float, float* %55, align 4, !tbaa !8
  %328 = tail call float @llvm.fmuladd.f32(float %326, float %327, float %325)
  %329 = load float, float* %57, align 4, !tbaa !8
  %330 = load float, float* %59, align 4, !tbaa !8
  %331 = tail call float @llvm.fmuladd.f32(float %329, float %330, float %328)
  %332 = load float, float* %61, align 4, !tbaa !8
  %333 = load float, float* %63, align 4, !tbaa !8
  %334 = tail call float @llvm.fmuladd.f32(float %332, float %333, float %331)
  %335 = load float, float* %65, align 4, !tbaa !8
  %336 = load float, float* %67, align 4, !tbaa !8
  %337 = tail call float @llvm.fmuladd.f32(float %335, float %336, float %334)
  %338 = load float, float* %69, align 4, !tbaa !8
  %339 = load float, float* %71, align 4, !tbaa !8
  %340 = tail call float @llvm.fmuladd.f32(float %338, float %339, float %337)
  %341 = load float, float* %73, align 4, !tbaa !8
  %342 = load float, float* %75, align 4, !tbaa !8
  %343 = tail call float @llvm.fmuladd.f32(float %341, float %342, float %340)
  %344 = load float, float* %77, align 4, !tbaa !8
  %345 = load float, float* %79, align 4, !tbaa !8
  %346 = tail call float @llvm.fmuladd.f32(float %344, float %345, float %343)
  %347 = load float, float* %81, align 4, !tbaa !8
  %348 = load float, float* %83, align 4, !tbaa !8
  %349 = tail call float @llvm.fmuladd.f32(float %347, float %348, float %346)
  %350 = load float, float* %85, align 4, !tbaa !8
  %351 = load float, float* %87, align 4, !tbaa !8
  %352 = tail call float @llvm.fmuladd.f32(float %350, float %351, float %349)
  %353 = load float, float* %89, align 4, !tbaa !8
  %354 = load float, float* %91, align 4, !tbaa !8
  %355 = tail call float @llvm.fmuladd.f32(float %353, float %354, float %352)
  %356 = load float, float* %93, align 4, !tbaa !8
  %357 = load float, float* %95, align 4, !tbaa !8
  %358 = tail call float @llvm.fmuladd.f32(float %356, float %357, float %355)
  %359 = load float, float* %97, align 4, !tbaa !8
  %360 = load float, float* %99, align 4, !tbaa !8
  %361 = tail call float @llvm.fmuladd.f32(float %359, float %360, float %358)
  %362 = load float, float* %101, align 4, !tbaa !8
  %363 = load float, float* %103, align 4, !tbaa !8
  %364 = tail call float @llvm.fmuladd.f32(float %362, float %363, float %361)
  %365 = load float, float* %105, align 4, !tbaa !8
  %366 = load float, float* %107, align 4, !tbaa !8
  %367 = tail call float @llvm.fmuladd.f32(float %365, float %366, float %364)
  %368 = load float, float* %109, align 4, !tbaa !8
  %369 = load float, float* %111, align 4, !tbaa !8
  %370 = tail call float @llvm.fmuladd.f32(float %368, float %369, float %367)
  %371 = load float, float* %113, align 4, !tbaa !8
  %372 = load float, float* %115, align 4, !tbaa !8
  %373 = tail call float @llvm.fmuladd.f32(float %371, float %372, float %370)
  %374 = load float, float* %117, align 4, !tbaa !8
  %375 = load float, float* %119, align 4, !tbaa !8
  %376 = tail call float @llvm.fmuladd.f32(float %374, float %375, float %373)
  %377 = load float, float* %121, align 4, !tbaa !8
  %378 = load float, float* %123, align 4, !tbaa !8
  %379 = tail call float @llvm.fmuladd.f32(float %377, float %378, float %376)
  %380 = load float, float* %125, align 4, !tbaa !8
  %381 = load float, float* %127, align 4, !tbaa !8
  %382 = tail call float @llvm.fmuladd.f32(float %380, float %381, float %379)
  %383 = load float, float* %129, align 4, !tbaa !8
  %384 = load float, float* %131, align 4, !tbaa !8
  %385 = tail call float @llvm.fmuladd.f32(float %383, float %384, float %382)
  %386 = load float, float* %133, align 4, !tbaa !8
  %387 = load float, float* %135, align 4, !tbaa !8
  %388 = tail call float @llvm.fmuladd.f32(float %386, float %387, float %385)
  %389 = load float, float* %137, align 4, !tbaa !8
  %390 = load float, float* %139, align 4, !tbaa !8
  %391 = tail call float @llvm.fmuladd.f32(float %389, float %390, float %388)
  %392 = load float, float* %141, align 4, !tbaa !8
  %393 = load float, float* %143, align 4, !tbaa !8
  %394 = tail call float @llvm.fmuladd.f32(float %392, float %393, float %391)
  %395 = load float, float* %145, align 4, !tbaa !8
  %396 = load float, float* %147, align 4, !tbaa !8
  %397 = tail call float @llvm.fmuladd.f32(float %395, float %396, float %394)
  %398 = load float, float* %149, align 4, !tbaa !8
  %399 = load float, float* %151, align 4, !tbaa !8
  %400 = tail call float @llvm.fmuladd.f32(float %398, float %399, float %397)
  %401 = load float, float* %153, align 4, !tbaa !8
  %402 = load float, float* %155, align 4, !tbaa !8
  %403 = tail call float @llvm.fmuladd.f32(float %401, float %402, float %400)
  %404 = load float, float* %157, align 4, !tbaa !8
  %405 = load float, float* %159, align 4, !tbaa !8
  %406 = tail call float @llvm.fmuladd.f32(float %404, float %405, float %403)
  %407 = load float, float* %161, align 4, !tbaa !8
  %408 = load float, float* %163, align 4, !tbaa !8
  %409 = tail call float @llvm.fmuladd.f32(float %407, float %408, float %406)
  %410 = load float, float* %165, align 4, !tbaa !8
  %411 = load float, float* %167, align 4, !tbaa !8
  %412 = tail call float @llvm.fmuladd.f32(float %410, float %411, float %409)
  %413 = load float, float* %169, align 4, !tbaa !8
  %414 = load float, float* %171, align 4, !tbaa !8
  %415 = tail call float @llvm.fmuladd.f32(float %413, float %414, float %412)
  %416 = load float, float* %173, align 4, !tbaa !8
  %417 = load float, float* %175, align 4, !tbaa !8
  %418 = tail call float @llvm.fmuladd.f32(float %416, float %417, float %415)
  %419 = load float, float* %177, align 4, !tbaa !8
  %420 = load float, float* %179, align 4, !tbaa !8
  %421 = tail call float @llvm.fmuladd.f32(float %419, float %420, float %418)
  %422 = load float, float* %181, align 4, !tbaa !8
  %423 = load float, float* %183, align 4, !tbaa !8
  %424 = tail call float @llvm.fmuladd.f32(float %422, float %423, float %421)
  %425 = load float, float* %185, align 4, !tbaa !8
  %426 = load float, float* %187, align 4, !tbaa !8
  %427 = tail call float @llvm.fmuladd.f32(float %425, float %426, float %424)
  %428 = load float, float* %189, align 4, !tbaa !8
  %429 = load float, float* %191, align 4, !tbaa !8
  %430 = tail call float @llvm.fmuladd.f32(float %428, float %429, float %427)
  %431 = load float, float* %193, align 4, !tbaa !8
  %432 = load float, float* %195, align 4, !tbaa !8
  %433 = tail call float @llvm.fmuladd.f32(float %431, float %432, float %430)
  %434 = load float, float* %197, align 4, !tbaa !8
  %435 = load float, float* %199, align 4, !tbaa !8
  %436 = tail call float @llvm.fmuladd.f32(float %434, float %435, float %433)
  %437 = load float, float* %201, align 4, !tbaa !8
  %438 = load float, float* %203, align 4, !tbaa !8
  %439 = tail call float @llvm.fmuladd.f32(float %437, float %438, float %436)
  %440 = load float, float* %205, align 4, !tbaa !8
  %441 = load float, float* %207, align 4, !tbaa !8
  %442 = tail call float @llvm.fmuladd.f32(float %440, float %441, float %439)
  %443 = load float, float* %209, align 4, !tbaa !8
  %444 = load float, float* %211, align 4, !tbaa !8
  %445 = tail call float @llvm.fmuladd.f32(float %443, float %444, float %442)
  %446 = load float, float* %213, align 4, !tbaa !8
  %447 = load float, float* %215, align 4, !tbaa !8
  %448 = tail call float @llvm.fmuladd.f32(float %446, float %447, float %445)
  %449 = load float, float* %217, align 4, !tbaa !8
  %450 = load float, float* %219, align 4, !tbaa !8
  %451 = tail call float @llvm.fmuladd.f32(float %449, float %450, float %448)
  %452 = load float, float* %221, align 4, !tbaa !8
  %453 = load float, float* %223, align 4, !tbaa !8
  %454 = tail call float @llvm.fmuladd.f32(float %452, float %453, float %451)
  %455 = load float, float* %225, align 4, !tbaa !8
  %456 = load float, float* %227, align 4, !tbaa !8
  %457 = tail call float @llvm.fmuladd.f32(float %455, float %456, float %454)
  %458 = load float, float* %229, align 4, !tbaa !8
  %459 = load float, float* %231, align 4, !tbaa !8
  %460 = tail call float @llvm.fmuladd.f32(float %458, float %459, float %457)
  %461 = load float, float* %233, align 4, !tbaa !8
  %462 = load float, float* %235, align 4, !tbaa !8
  %463 = tail call float @llvm.fmuladd.f32(float %461, float %462, float %460)
  %464 = load float, float* %237, align 4, !tbaa !8
  %465 = load float, float* %239, align 4, !tbaa !8
  %466 = tail call float @llvm.fmuladd.f32(float %464, float %465, float %463)
  %467 = load float, float* %241, align 4, !tbaa !8
  %468 = load float, float* %243, align 4, !tbaa !8
  %469 = tail call float @llvm.fmuladd.f32(float %467, float %468, float %466)
  %470 = load float, float* %245, align 4, !tbaa !8
  %471 = load float, float* %247, align 4, !tbaa !8
  %472 = tail call float @llvm.fmuladd.f32(float %470, float %471, float %469)
  %473 = load float, float* %249, align 4, !tbaa !8
  %474 = load float, float* %251, align 4, !tbaa !8
  %475 = tail call float @llvm.fmuladd.f32(float %473, float %474, float %472)
  %476 = load float, float* %253, align 4, !tbaa !8
  %477 = load float, float* %255, align 4, !tbaa !8
  %478 = tail call float @llvm.fmuladd.f32(float %476, float %477, float %475)
  %479 = load float, float* %257, align 4, !tbaa !8
  %480 = load float, float* %259, align 4, !tbaa !8
  %481 = tail call float @llvm.fmuladd.f32(float %479, float %480, float %478)
  %482 = load float, float* %261, align 4, !tbaa !8
  %483 = load float, float* %263, align 4, !tbaa !8
  %484 = tail call float @llvm.fmuladd.f32(float %482, float %483, float %481)
  %485 = load float, float* %265, align 4, !tbaa !8
  %486 = load float, float* %267, align 4, !tbaa !8
  %487 = tail call float @llvm.fmuladd.f32(float %485, float %486, float %484)
  %488 = load float, float* %269, align 4, !tbaa !8
  %489 = load float, float* %271, align 4, !tbaa !8
  %490 = tail call float @llvm.fmuladd.f32(float %488, float %489, float %487)
  %491 = load float, float* %273, align 4, !tbaa !8
  %492 = load float, float* %275, align 4, !tbaa !8
  %493 = tail call float @llvm.fmuladd.f32(float %491, float %492, float %490)
  %494 = load float, float* %277, align 4, !tbaa !8
  %495 = load float, float* %279, align 4, !tbaa !8
  %496 = tail call float @llvm.fmuladd.f32(float %494, float %495, float %493)
  %497 = load float, float* %281, align 4, !tbaa !8
  %498 = load float, float* %283, align 4, !tbaa !8
  %499 = tail call float @llvm.fmuladd.f32(float %497, float %498, float %496)
  %500 = load float, float* %285, align 4, !tbaa !8
  %501 = load float, float* %287, align 4, !tbaa !8
  %502 = tail call float @llvm.fmuladd.f32(float %500, float %501, float %499)
  %503 = load float, float* %289, align 4, !tbaa !8
  %504 = load float, float* %291, align 4, !tbaa !8
  %505 = tail call float @llvm.fmuladd.f32(float %503, float %504, float %502)
  %506 = load float, float* %293, align 4, !tbaa !8
  %507 = load float, float* %295, align 4, !tbaa !8
  %508 = tail call float @llvm.fmuladd.f32(float %506, float %507, float %505)
  tail call void @_Z7barrierj(i32 1) #5
  %509 = add i64 %302, 64
  %510 = add i64 %303, %40
  %511 = icmp slt i64 %509, %42
  br i1 %511, label %301, label %296

; <label>:512:                                    ; preds = %296
  %513 = tail call i64 @_Z15get_global_sizej(i32 0) #4
  %514 = mul i64 %513, %298
  %515 = tail call i64 @_Z13get_global_idj(i32 0) #4
  %516 = add i64 %514, %515
  %517 = getelementptr inbounds float, float* %0, i64 %516
  store float %297, float* %517, align 4, !tbaa !8
  br label %518

; <label>:518:                                    ; preds = %512, %296
  ret void
}

; Function Attrs: nounwind readnone
declare i64 @_Z12get_group_idj(i32) local_unnamed_addr #1

; Function Attrs: nounwind readnone
declare i64 @_Z12get_local_idj(i32) local_unnamed_addr #1

; Function Attrs: convergent
declare void @_Z7barrierj(i32) local_unnamed_addr #2

; Function Attrs: nounwind readnone speculatable
declare float @llvm.fmuladd.f32(float, float, float) #3

; Function Attrs: nounwind readnone
declare i64 @_Z13get_global_idj(i32) local_unnamed_addr #1

; Function Attrs: nounwind readnone
declare i64 @_Z15get_global_sizej(i32) local_unnamed_addr #1

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="penryn" "target-features"="+cx16,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nounwind readnone "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="penryn" "target-features"="+cx16,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { convergent "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="true" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="penryn" "target-features"="+cx16,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nounwind readnone speculatable }
attributes #4 = { nounwind readnone }
attributes #5 = { convergent nounwind }

!llvm.module.flags = !{!0, !1}
!opencl.ocl.version = !{!2}
!llvm.ident = !{!3}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{i32 1, i32 0}
!3 = !{!"Apple LLVM version 9.1.0 (clang-902.0.39.1)"}
!4 = !{i32 1, i32 1, i32 1, i32 3, i32 3, i32 0, i32 0, i32 0}
!5 = !{!"none", !"none", !"none", !"none", !"none", !"none", !"none", !"none"}
!6 = !{!"float*", !"float*", !"float*", !"float*", !"float*", !"int", !"int", !"int"}
!7 = !{!"", !"", !"", !"", !"", !"", !"", !""}
!8 = !{!9, !9, i64 0}
!9 = !{!"float", !10, i64 0}
!10 = !{!"omnipotent char", !11, i64 0}
!11 = !{!"Simple C/C++ TBAA"}
